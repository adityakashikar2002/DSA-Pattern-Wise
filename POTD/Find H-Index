// Brute Force
// Time: O(nÂ²)
// Space: O(1)
----------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------
class Solution {
    public int hIndex(int[] citations) {
        int n = citations.length;
        int maxH = 0;
        
        Arrays.sort(citations);
        
        for(int h = 1; h <= n; h++) {
            int count = 0;
            
            for(int j = 0; j < n; j++) 
            {
                if(citations[j] >= h)
                    count++;
            }
            
            if(count >= h)
                maxH = h;
        }
        
        return maxH;
    }
}

----------------------------------------------------------------------
Better Approach
----------------------------------------------------
// Time: O(n log n) (sorting)
// Space: O(1)
----------------------------------------------------
class Solution {
    public int hIndex(int[] citations) {
        // code here
        
        int n = citations.length;
        
        Arrays.sort(citations);
        int ans = 0;
        
        for(int i = 0; i < n; i++)
        {
            if(citations[i]  >= n - i)
            {
                ans = Math.max(ans, citations[i]); 
                break;
            }
                
        }
        
        return ans;
    }
}
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Optimal Approach
----------------------------------------------------
// Time: O(n) (counting + single pass)
// Space: O(n) (bucket array)
----------------------------------------------------
Imagine youâ€™re checking how many papers a researcher has that are â€œgood enoughâ€ to give them a certain H-index. The H-index means: "You have at least h papers with at least h citations each."

Now instead of sorting the whole list (which takes extra time), we use a frequency counter (freq) where we just count how many papers have exactly 0 citations, how many have 1, how many have 2, and so on. But if a paper has a very high number of citations (say bigger than the total number of papers), it doesnâ€™t really matter how much higherâ€”it can only help up to n (the total number of papers). So we just dump all those â€œsuper high citationâ€ papers into the bucket freq[n].

After this, we go backwards from the largest possible h (which is n) down to 0. While going, we keep adding up how many papers have at least that many citations. The moment we find that the number of papers is greater than or equal to the citation count weâ€™re testing, thatâ€™s the H-index.

So basically:
ğŸ‘‰ Count papers by citation buckets.
ğŸ‘‰ Start from the top and see the largest h for which at least h papers exist.
ğŸ‘‰ Return that as the H-index.

Itâ€™s like saying: â€œHow many strong papers do you have? Letâ€™s test from the maximum possible strength down until the condition is satisfied.â€
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
class Solution {
    public int hIndex(int[] citations) {
        // code here
        int n = citations.length;
        
        int[] freq = new int[n + 1];
        
        for(int i = 0; i < n; i++)
        {   
            if(citations[i] >= n)
                freq[n]++;
            else
                freq[citations[i]]++;
        }
        
        int c = 0;
        
        for(int i = n; i >= 0; i--)
        {
            c = c + freq[i];
            
            if(c >= i)
                return i;
        }
        
        return 0;
    }
}
